{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import active_children\n",
    "import os\n",
    "from re import I\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import activations\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Lambda, Concatenate, Reshape, Add, Dropout\n",
    "from keras.layers import MultiHeadAttention\n",
    "from keras.models import Model \n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from myattention import Attention\n",
    "from layers import Aggregate\n",
    "from load import load_data, load_cla_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_path, fname):\n",
    "    df = pd.read_csv(data_path + fname)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values(by='Date').reset_index(drop=True)\n",
    "    df['Close-1'] = df['Close'].shift(1)\n",
    "    try: \n",
    "        df['c_open'] = (df['Original_Open']/df['Close']) - 1\n",
    "    except:\n",
    "        df['c_open'] = (df['Open']/df['Close']) - 1\n",
    "    df['c_high'] = df['High']/df['Close'] - 1\n",
    "    df['c_low'] = df['Low']/df['Close'] - 1\n",
    "    df['c_close'] = df['Close']/df['Close-1'] - 1\n",
    "\n",
    "    df['adj_close-1'] = df['Adj Close'].shift(1)\n",
    "    df['c_adj_close'] = df['Adj Close']/df['adj_close-1'] -1\n",
    "\n",
    "    df['adj_close+1'] = df['Adj Close'].shift(-1)\n",
    "    df['c_adj_close+1'] = df['adj_close+1']/df['Adj Close'] -1\n",
    "\n",
    "    df['c_5'] = (df['Adj Close'].rolling(5).sum()/(5*df['Adj Close'])) - 1\n",
    "    df['c_10'] = (df['Adj Close'].rolling(10).sum()/(10*df['Adj Close'])) - 1\n",
    "    df['c_15'] = (df['Adj Close'].rolling(15).sum()/(15*df['Adj Close'])) - 1\n",
    "    df['c_20'] = (df['Adj Close'].rolling(20).sum()/(20*df['Adj Close'])) - 1\n",
    "    df['c_25'] = (df['Adj Close'].rolling(25).sum()/(25*df['Adj Close'])) - 1\n",
    "    df['c_30'] = (df['Adj Close'].rolling(30).sum()/(30*df['Adj Close'])) - 1\n",
    "    df['c_label'] = 0\n",
    "    # df.loc[df['c_adj_close'] > 0.0055, 'c_label'] = 1\n",
    "    # df.loc[df['c_adj_close'] < -0.005, 'c_label'] = -1\n",
    "\n",
    "    # df.loc[df['c_adj_close+1'] > 0.0055, 'c_label'] = 1\n",
    "    # df.loc[df['c_adj_close+1'] < -0.005, 'c_label'] = -1\n",
    "    df.loc[df['c_adj_close+1'] >= 0, 'c_label'] = 1\n",
    "    df.loc[df['c_adj_close+1'] < 0, 'c_label'] = -1\n",
    "    df = df[['c_open', 'c_high', 'c_low', 'c_close','c_adj_close','c_5', 'c_10', 'c_15', 'c_20', 'c_25','c_30', 'c_label', 'Adj Close']]\n",
    "    # df = df.iloc[:-1,:]\n",
    "    df.iloc[:29, :] = -123321.000000\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index \n",
    "processed_df = preprocess('./data/index/raw/', 'SPY.csv')\n",
    "processed_df.to_csv('./data/index/preprocessed/'+ 'snp500_p.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks\n",
    "data_path = './data/kdd17/price_long_50/'\n",
    "fnames = [fname for fname in os.listdir(data_path) if\n",
    "            os.path.isfile(os.path.join(data_path, fname))]\n",
    "for fname in fnames:\n",
    "    processed_df = preprocess(data_path, fname)\n",
    "    processed_df.to_csv('./data/kdd17/processed/' + fname, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model and test wtih dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"feature_dim\": 11,\n",
    "    \"ticker_size\": 2,\n",
    "}\n",
    "\n",
    "time_steps=3\n",
    "units=11\n",
    "\n",
    "index_X_train = np.array([[[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                   [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                   [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                   [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                   [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                   [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                   [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                   [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                   [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                   [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                   [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                   [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                   [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                   [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                   [3,4,5,6,7,8,9,10,11,12,13]],])\n",
    "stock1 = np.array([[[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],])\n",
    "stock2 = np.array([[[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],\n",
    "                [[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]],])\n",
    "stock_X_train_list = [stock1, stock2]\n",
    "y_train = np.array([[1,0],\n",
    "                    [1,0],\n",
    "                    [0,0],\n",
    "                    [0,1],\n",
    "                    [1,1]])\n",
    "\n",
    "test = np.array([[[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 14:58:05.573787: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2, 11)\n",
      "(None, 2, 1)\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 14:58:11.777891: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-07-29 14:58:11.778081: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-07-29 14:58:11.778227: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2600 num_cores: 12 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 12582912 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 0.5000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4999\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4999\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4994\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9fc511c5b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_axis_attention(model_input, feature_dim, units):\n",
    "    x = Dense(feature_dim, activation='tanh')(model_input)\n",
    "    x = LSTM(units, return_sequences=True)(x)\n",
    "    x = Attention(feature_dim)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "index_input = Input(shape=(time_steps, params['feature_dim']), name='index_input')\n",
    "index_model = time_axis_attention(index_input, params['feature_dim'], units)\n",
    "# index_model = Model(inputs=index_input, outputs=index_model)\n",
    "\n",
    "stock_input_list = [Input(shape=(time_steps, params['feature_dim'])) for stock_input in range(params['ticker_size'])]\n",
    "\n",
    "context_aggs = [None]*(params['ticker_size'])\n",
    "for i in range(params['ticker_size']):\n",
    "    stock_input = stock_input_list[i]\n",
    "    stock_model = time_axis_attention(stock_input, params['feature_dim'], units)\n",
    "    # stock_model = Model(inputs=stock_input, outputs=stock_model)\n",
    "    context_aggs[i] = Aggregate(units)([index_model, stock_model])\n",
    "\n",
    "x = context_aggs[0]\n",
    "for i in range(1, params['ticker_size']):\n",
    "    x = Concatenate()([x, context_aggs[i]])\n",
    "x = Reshape((params['ticker_size'], -1))(x)\n",
    "print(x.shape)\n",
    "\n",
    "# Data Axis context\n",
    "mha = MultiHeadAttention(num_heads=2, key_dim=2)(x, x)\n",
    "# Nonlinear Transformation\n",
    "addition = Add()([x, mha])\n",
    "x = Dense(units)(addition)\n",
    "x = Add()([addition, x])\n",
    "x = Dropout(rate=0.2)(x)\n",
    "x = activations.tanh(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "print(x.shape)\n",
    "model = Model(inputs=[index_input, *stock_input_list], outputs=x)\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "plot_model(model, to_file='./image/model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "model.fit(x =[index_X_train, stock_X_train_list], y=y_train ,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.4407476 ],\n",
       "        [0.42292118]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_X_test = np.array([[[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                   [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                   [3,4,5,6,7,8,9,10,11,12,13]]])\n",
    "\n",
    "stock1_test = np.array([[[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]]])\n",
    "stock2_test = np.array([[[1,2,3,4,5,6,7,8,9,10,11],\n",
    "                [2,3,4,5,6,7,8,9,10,11,12],\n",
    "                [3,4,5,6,7,8,9,10,11,12,13]]])\n",
    "stock_X_test_list = [stock1_test, stock2_test]\n",
    "pred = model.predict([index_X_test, stock_X_test_list])\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1021d077b7873670e1beefb758f64d1cb6dee6622cc6b5e630350531058a0bc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
