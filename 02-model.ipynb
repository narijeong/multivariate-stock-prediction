{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49  tickers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from attention import Attention\n",
    "from load import load_data\n",
    "from aggregate import Aggregate\n",
    "\n",
    "tra_date = '2007-02-14'\n",
    "val_date = '2015-01-02'\n",
    "tes_date = '2016-01-04'\n",
    "model_selection = 'dtml'\n",
    "\n",
    "index_data_path = './data/kdd17/index/'\n",
    "index_fname = 'SPY_processed.csv'\n",
    "data_path = './data/kdd17/processed/'\n",
    "num_tickers = 50\n",
    "params = {\n",
    "    'input_dim': 11,\n",
    "    'time_steps': 15,\n",
    "    'epochs': 5,\n",
    "}\n",
    "\n",
    "fnames = [fname for fname in os.listdir(data_path) if\n",
    "            os.path.isfile(os.path.join(data_path, fname))]\n",
    "print(len(fnames), ' tickers')\n",
    "\n",
    "stock_layers = [x[:-4] for x in fnames]\n",
    "\n",
    "\n",
    "stock_context_vector = np.zeros([50, 1970, 11], dtype=float)\n",
    "index_context_vector = np.zeros([1, 1970, 11], dtype=float)\n",
    "\n",
    "stock_model = []\n",
    "aggreated_model = []\n",
    "\n",
    "def time_axis_attention(data_path, fname):\n",
    "    print(fname)\n",
    "    tra_pv, tra_wd, tra_gt, val_pv, val_wd, val_gt, tes_pv, tes_wd, tes_gt = load_data(data_path, fname,\n",
    "            tra_date, val_date, tes_date, seq=params['time_steps']\n",
    "        ) \n",
    "    model_input = Input(shape=(params['time_steps'], params['input_dim']))\n",
    "    x = Dense(params['input_dim'])(model_input)\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Attention(params['input_dim'])(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    model = Model(model_input, x)\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # context vector\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[-1].output)\n",
    "    intermediate_output = intermediate_layer_model(tra_pv).numpy()\n",
    "    return intermediate_output\n",
    "\n",
    "    # x = Dense(1, activation = 'sigmoid')(x)\n",
    "    # x = Dense(1)(x)\n",
    "    # model = Model(model_input, x)\n",
    "    # model.compile(loss='mae', optimizer='adam')\n",
    "    # model.summary()\n",
    "\n",
    "    # save context vector\n",
    "    # intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[-1].output)\n",
    "    # intermediate_output = intermediate_layer_model(tra_pv)\n",
    "    # stock_context_vector[idx] = intermediate_output.numpy()\n",
    "\n",
    "    # model.fit(tra_pv, tra_gt, epochs=params['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY_processed.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "252  testing instances\n",
      "BA.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "TM.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "MO.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "NVS.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "T.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "DCM.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "CHL.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "BAC.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "PEP.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "VALE.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "D.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "MRK.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "ORCL.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "PG.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "AMZN.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "INTC.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "MMM.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "KO.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "UPS.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "MSFT.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "TOT.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "EXC.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "HD.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "SO.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "XOM.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "CVX.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "RDS-B.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "CMCSA.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "NGG.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "BHP.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "WFC.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "DIS.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "GE.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "PTR.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "JPM.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "GOOGL.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "PFE.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "DUK.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "VZ.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "UNH.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "MA.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "SYT.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "AAPL.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "WMT.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "NTT.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "RIO.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "BRK-B.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "DOW.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n",
      "JNJ.csv\n",
      "1  tickers selected\n",
      "2518 trading dates:\n",
      "29 2014 2266\n",
      "1970  training instances\n",
      "252  validation instances\n",
      "data_EOD 2518\n",
      "251  testing instances\n"
     ]
    }
   ],
   "source": [
    "index_context_vector = time_axis_attention(index_data_path, index_fname)\n",
    "for idx, fname in enumerate(fnames):\n",
    "    stock_context_vector[idx] = time_axis_attention(data_path, fname)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_model():\n",
    "    model_input = Input(shape=(params['time_steps'], params['input_dim']))\n",
    "    x = Dense(params['input_dim'])(model_input)\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Attention(params['input_dim'])(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01392356, -0.00018619, -0.00656118, ...,  0.00435714,\n",
       "        -0.01140799,  0.00162378],\n",
       "       [-0.01207639, -0.00022943, -0.00734343, ...,  0.0032198 ,\n",
       "        -0.0103576 ,  0.00117521],\n",
       "       [-0.01013519, -0.00050935, -0.00874232, ...,  0.00221726,\n",
       "        -0.00900753,  0.00061732],\n",
       "       ...,\n",
       "       [ 0.00362593,  0.00111953, -0.00141175, ..., -0.00125042,\n",
       "         0.00311573, -0.00240044],\n",
       "       [ 0.00325921,  0.00122984, -0.00060503, ..., -0.00086837,\n",
       "         0.00203469, -0.00156328],\n",
       "       [ 0.00216491,  0.00141626,  0.00057647, ..., -0.00015327,\n",
       "         0.000624  , -0.00071362]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_model = get_attention_model()\n",
    "\n",
    "model_input = Input(shape=(params['time_steps'], params['input_dim']))\n",
    "for idx, fname in fnames:\n",
    "    stock_model[idx] = get_attention_model()\n",
    "    aggreated_model[idx] = Model(model_input, x)\n",
    "    aggreated_model[idx] = Aggregate(params['input_dim'])([index_model, stock_model])\n",
    "    stock_model[idx].compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context vector\n",
    "for idx, fname in fnames:\n",
    "    model = stock_model[idx]\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[-1].output)\n",
    "    intermediate_output = intermediate_layer_model(tra_pv).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1970, 11), dtype=float32, numpy=\n",
       "array([[ 5.4233335e-03,  2.4390398e-03,  2.3545958e-03, ...,\n",
       "        -7.7093550e-04,  5.6178048e-03,  2.4059550e-03],\n",
       "       [ 4.6143364e-03,  2.5975327e-03,  2.0954572e-03, ...,\n",
       "        -4.4679292e-04,  5.4750405e-03,  2.8891736e-03],\n",
       "       [ 4.0299036e-03,  2.5541140e-03,  1.9977712e-03, ...,\n",
       "        -3.4593028e-04,  5.4613161e-03,  3.3186213e-03],\n",
       "       ...,\n",
       "       [ 3.2325275e-04, -4.8872544e-03, -1.0408924e-02, ...,\n",
       "         2.0146335e-03, -9.7539620e-03, -1.1712414e-03],\n",
       "       [ 1.5361602e-03, -3.7946980e-03, -1.1651803e-02, ...,\n",
       "         2.6936331e-03, -1.0067202e-02,  9.5471914e-06],\n",
       "       [ 2.4166857e-03, -2.8484033e-03, -1.0264205e-02, ...,\n",
       "         2.5905017e-03, -8.8460771e-03, -1.9430008e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def context_aggregation():\n",
    "#     for stock in stock_context_vector:\n",
    "#         merged = Aggregate(index.shape[1])([index, stock])\n",
    "Aggregate(11)([index, apple])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [fname for fname in os.listdir(data_path) if\n",
    "            os.path.isfile(os.path.join(data_path, fname))]\n",
    "print(len(fnames), ' tickers')\n",
    "\n",
    "\n",
    "for idx, fname in enumerate(fnames):\n",
    "    print(fname)\n",
    "    tra_pv, tra_wd, tra_gt, val_pv, val_wd, val_gt, tes_pv, tes_wd, tes_gt = load_data(data_path, fname,\n",
    "            tra_date, val_date, tes_date, seq=params['time_steps']\n",
    "        ) \n",
    "    model_input = Input(shape=(params['time_steps'], params['input_dim']))\n",
    "    x = Dense(params['input_dim'])(model_input)\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Attention(params['input_dim'])(x)\n",
    "    # x = Dense(1, activation = 'sigmoid')(x)\n",
    "    # x = Dense(1)(x)\n",
    "    model = Model(model_input, x)\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.summary()\n",
    "\n",
    "    # save context vector\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[-1].output)\n",
    "    intermediate_output = intermediate_layer_model(tra_pv)\n",
    "    stock_context_vector[idx] = intermediate_output.numpy()\n",
    "\n",
    "    model.fit(tra_pv, tra_gt, epochs=params['epochs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3.94268474e-03, -7.68327503e-04, -7.77846617e-06, ...,\n",
       "          2.55864183e-03,  6.68808771e-03, -5.28394943e-03],\n",
       "        [-3.91988689e-03, -1.85969948e-05,  2.78514519e-04, ...,\n",
       "          1.62527629e-03,  5.63550927e-03, -4.83782729e-03],\n",
       "        [-3.79534112e-03,  1.00350915e-03,  9.82391415e-04, ...,\n",
       "          5.01917093e-04,  4.61288402e-03, -4.38891398e-03],\n",
       "        ...,\n",
       "        [-1.74346031e-03,  7.89974071e-03,  4.27981466e-03, ...,\n",
       "          3.17770580e-04, -2.28511728e-03, -3.51359812e-03],\n",
       "        [-2.32273655e-04,  7.64224492e-03,  4.28253319e-03, ...,\n",
       "         -1.69997814e-03, -5.04839048e-03, -1.16537570e-03],\n",
       "        [ 1.41247991e-03,  6.23681024e-03,  3.40810209e-03, ...,\n",
       "         -2.51824432e-03, -7.17436662e-03,  1.18894898e-03]],\n",
       "\n",
       "       [[-3.23717296e-03, -3.93352332e-03, -9.29951435e-04, ...,\n",
       "          3.58164334e-03,  9.75792296e-03, -3.78302950e-03],\n",
       "        [-3.66728404e-03, -3.00392136e-03,  1.05192745e-03, ...,\n",
       "          1.20060355e-03,  7.98861310e-03, -3.61817144e-03],\n",
       "        [-3.38099222e-03, -2.69271852e-03,  1.16421178e-03, ...,\n",
       "          6.76233962e-04,  5.93427708e-03, -3.28774797e-03],\n",
       "        ...,\n",
       "        [-6.29618345e-03,  2.52887211e-03,  1.89178239e-03, ...,\n",
       "         -1.07315276e-02,  3.87259806e-03, -3.36790225e-04],\n",
       "        [-5.64187998e-03,  3.00414185e-03,  1.80199277e-03, ...,\n",
       "         -1.04034012e-02,  1.90033298e-03, -2.35136016e-04],\n",
       "        [-4.72271070e-03,  2.67485646e-03,  7.76581350e-04, ...,\n",
       "         -8.46760534e-03,  1.04847783e-03, -3.72369628e-04]],\n",
       "\n",
       "       [[-1.38566911e-03,  3.19340010e-03,  2.38201488e-03, ...,\n",
       "          8.03811662e-03,  1.11150315e-04, -1.54608744e-03],\n",
       "        [-1.93465815e-03,  4.22656629e-03,  3.56181804e-03, ...,\n",
       "          5.23258606e-03, -1.97409117e-03, -3.07177455e-04],\n",
       "        [-2.16283277e-03,  5.84969064e-03,  4.99170180e-03, ...,\n",
       "          1.85870705e-03, -4.85320436e-03,  1.25691073e-03],\n",
       "        ...,\n",
       "        [-1.32715772e-03,  5.73008554e-04,  2.20651273e-03, ...,\n",
       "         -6.53827470e-03, -1.74489582e-03,  1.23545164e-04],\n",
       "        [-1.27316476e-03,  2.59630033e-04,  1.43161824e-03, ...,\n",
       "         -5.83028747e-03, -1.83872110e-03,  2.15126478e-04],\n",
       "        [-9.66110558e-04, -4.57018788e-04,  5.51813107e-04, ...,\n",
       "         -4.19870205e-03, -8.60357773e-04, -8.97726495e-05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.77034677e-03,  1.37608193e-04,  1.94392560e-04, ...,\n",
       "          4.58571734e-03, -1.59765827e-03, -1.55311252e-03],\n",
       "        [-1.57918176e-03,  1.23996579e-03,  1.32468471e-03, ...,\n",
       "          2.35804869e-03, -3.42254993e-03, -7.24870537e-04],\n",
       "        [-1.00478064e-03,  1.51071860e-03,  1.96617935e-03, ...,\n",
       "          3.35562872e-05, -4.86518117e-03,  5.99084829e-04],\n",
       "        ...,\n",
       "        [-2.78090755e-03,  1.13881927e-03,  1.72721513e-03, ...,\n",
       "         -9.72272269e-03,  8.31091485e-04,  4.95188462e-04],\n",
       "        [-2.42932281e-03,  1.63187075e-03,  1.88994175e-03, ...,\n",
       "         -9.54202656e-03,  1.64124256e-04,  4.46418242e-04],\n",
       "        [-2.10904889e-03,  2.03106715e-03,  1.80573447e-03, ...,\n",
       "         -9.15879291e-03, -6.21705083e-04,  3.53747600e-04]],\n",
       "\n",
       "       [[-3.53106577e-03, -8.01474694e-03, -4.05588048e-03, ...,\n",
       "         -5.71075315e-03,  7.12714577e-03, -2.71507166e-03],\n",
       "        [-3.93235171e-03, -6.48562098e-03, -2.83080735e-03, ...,\n",
       "         -5.63205453e-03,  7.66942138e-03, -3.72423744e-03],\n",
       "        [-4.33365908e-03, -4.91101528e-03, -2.03593983e-03, ...,\n",
       "         -5.92252752e-03,  7.19835563e-03, -3.88147146e-03],\n",
       "        ...,\n",
       "        [ 2.60453764e-03,  1.11263795e-02,  2.32340209e-03, ...,\n",
       "          2.88915671e-02,  7.80046685e-03, -1.21572847e-02],\n",
       "        [ 3.12202913e-03,  1.16100302e-02,  2.96711084e-03, ...,\n",
       "          2.74919961e-02,  3.05124070e-03, -9.13044717e-03],\n",
       "        [ 3.95698892e-03,  1.18329385e-02,  3.96621367e-03, ...,\n",
       "          2.58875303e-02, -1.33289490e-03, -6.21597376e-03]],\n",
       "\n",
       "       [[ 1.27635221e-03, -1.31329289e-03,  1.38519786e-03, ...,\n",
       "          1.93336140e-02,  9.12412629e-03, -7.81416893e-03],\n",
       "        [ 8.08300334e-04, -7.35435984e-04,  2.37198966e-03, ...,\n",
       "          1.97011996e-02,  8.95087048e-03, -8.04427266e-03],\n",
       "        [ 3.51603347e-04,  3.74117517e-04,  3.93374916e-03, ...,\n",
       "          1.91843826e-02,  8.00884888e-03, -7.98110384e-03],\n",
       "        ...,\n",
       "        [-9.47239343e-04,  1.75266556e-04,  2.34339549e-03, ...,\n",
       "          8.08890536e-03,  3.61288874e-03, -4.35112463e-03],\n",
       "        [-1.23468321e-03,  1.10254192e-03,  3.13701504e-03, ...,\n",
       "          7.87240267e-03,  2.36131158e-03, -4.46197623e-03],\n",
       "        [-1.44882000e-03,  1.47850940e-03,  3.65632097e-03, ...,\n",
       "          7.84429815e-03,  1.52064231e-03, -4.24396386e-03]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_level_context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(1, 3)\n",
      "(2, 3)\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# get context vector for index\n",
    "tra_pv, tra_wd, tra_gt, val_pv, val_wd, val_gt, tes_pv, tes_wd, tes_gt = load_data(data_path, fname,\n",
    "        tra_date, val_date, tes_date, seq=params['time_steps']\n",
    "    ) \n",
    "model_input = Input(shape=(params['time_steps'], params['input_dim']))\n",
    "x = Dense(params['input_dim'])(model_input)\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "x = Attention(params['input_dim'])(x)\n",
    "# x = Dense(1, activation = 'sigmoid')(x)\n",
    "# x = Dense(1)(x)\n",
    "model = Model(model_input, x)\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "# save context vector\n",
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[-1].output)\n",
    "intermediate_output = intermediate_layer_model(tra_pv)\n",
    "multi_level_context_vector[idx] = intermediate_output.numpy()\n",
    "\n",
    "model.fit(tra_pv, tra_gt, epochs=params['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 0.]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.empty((0,3))\n",
    "print(arr)\n",
    "arr = np.append(arr, np.array([[1, 2, 3]]), axis=0)\n",
    "arr = np.append(arr, np.array([[4, 5, 0]]), axis=0)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1021d077b7873670e1beefb758f64d1cb6dee6622cc6b5e630350531058a0bc8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a39a2dbc1b0080d8d73a667c0a770303b80bfa16b99e3cad7bfe1efe562f6dfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
